{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1U4qOjUj7vzkGVoPnvQVZMGzgzAyrfVoG",
      "authorship_tag": "ABX9TyMtYcCCNBqjsy6du5yECtX1"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# importing libraries\n",
        "\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import zipfile\n",
        "import cv2\n",
        "import h5py\n",
        "from keras import backend as K\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, BatchNormalization, Activation, MaxPooling2D\n",
        "from keras.layers import Flatten, Dense\n",
        "from os import listdir\n",
        "from os.path import isfile, join\n",
        "import sys\n",
        "import dlib\n",
        "\n",
        "\n",
        "# # !sudo pip3 install imageio==2.4.1\n",
        "# !pip install moviepy\n",
        "# !pip3 install imageio==2.4.1\n",
        "# !pip install --upgrade imageio-ffmpeg\n",
        "# !pip install imageio-ffmpeg\n",
        "# import imageio\n",
        "# # import imageio.v3 as iio\n",
        "# import moviepy.editor as mpy\n",
        "\n",
        "\n",
        "import wave\n",
        "import contextlib"
      ],
      "metadata": {
        "id": "yyR0WOQ8gMVz"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install speechpy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "47fpMM1VhdNr",
        "outputId": "da7d7dd2-1ab7-45ed-b1ee-4d4f3e8fba1d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting speechpy\n",
            "  Downloading speechpy-2.4-py2.py3-none-any.whl (9.5 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from speechpy) (1.21.6)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from speechpy) (1.7.3)\n",
            "Installing collected packages: speechpy\n",
            "Successfully installed speechpy-2.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import speechpy\n",
        "import scipy.io.wavfile as wav"
      ],
      "metadata": {
        "id": "murU5dkGhgwP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # mounting drive\n",
        "\n",
        "# from google.colab import drive\n",
        "# drive.mount('/content/gdrive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I2KjPDyUhjHh",
        "outputId": "b1fc040f-1f20-45cf-fba4-fc8d32a9f91e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# zipped vidtimit files\n",
        "path = '/content/drive/MyDrive/second_case_study_FILES'\n",
        "\n",
        "data_files = os.listdir(path)\n",
        "len(data_files)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q5g26uOChqg5",
        "outputId": "b1d474df-2e65-4c78-e1e6-bd68aeb0b261"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "43"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# unzipping all the zip files \n",
        "\n",
        "for i in data_files:\n",
        "  with zipfile.ZipFile('/content/drive/My Drive/second_case_study_FILES/'+i, 'r') as zip_ref:\n",
        "    zip_ref.extractall('/content/drive/My Drive/VIDTIMIT/')"
      ],
      "metadata": {
        "id": "dTlGnca1hxfz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# unzipped audios and images for 43 users\n",
        "data_files = os.listdir('/content/drive/My Drive/VIDTIMIT')\n",
        "len(data_files)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B8ZTrfCHh3Fc",
        "outputId": "08c95d7a-de1e-499f-f780-e3fcdca3ac7c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "43"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# https://stackoverflow.com/questions/30008859/how-to-create-a-video-with-raw-images-rgb-format-and-add-audio-to-it-in-pytho\n",
        "# https://stackoverflow.com/questions/7833807/get-wav-file-length-or-duration\n",
        "# https://zulko.github.io/moviepy/getting_started/getting_started.html\n",
        "# https://theailearner.com/2018/10/15/creating-video-from-images-using-opencv-python/\n",
        "\n",
        "import glob"
      ],
      "metadata": {
        "id": "Vn5sg7-hnjKv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "c=0\n",
        "for i in data_files:\n",
        "  # i represents user\n",
        "  c=c+1\n",
        "  print('file num',c,i)\n",
        "  files=os.listdir('/content/drive/My Drive/VIDTIMIT/'+i+'/audio')\n",
        "  for j in files:\n",
        "    # j represents audio file\n",
        "    \n",
        "    with contextlib.closing(wave.open('/content/drive/My Drive/VIDTIMIT/'+str(i)+'/audio/'+j,'r')) as f:\n",
        "      frames = f.getnframes()\n",
        "      rate = f.getframerate()\n",
        "      duration = frames / float(rate)\n",
        "      #print(duration)\n",
        "      \n",
        "    t = j.split('.')[0]\n",
        "    p = '/content/drive/My Drive/VIDTIMIT/'+i+'/video'\n",
        "    if t in os.listdir(p):\n",
        "        temp = os.listdir('/content/drive/My Drive/VIDTIMIT/'+i+'/video/'+t)\n",
        "        frames = len(temp)\n",
        "        fps = frames/duration\n",
        "        img_array = []\n",
        "        for filename in glob.glob('/content/drive/My Drive/VIDTIMIT/'+i+'/video/'+t+'/*'):\n",
        "            img = cv2.imread(filename)\n",
        "            height, width, layers = img.shape\n",
        "            size = (width,height)\n",
        "            img_array.append(img)\n",
        "        out = cv2.VideoWriter('/content/drive/My Drive/vidtimit_videos/non_tampered/'+i+'_'+t+'.mp4',cv2.VideoWriter_fourcc(*'DIVX'), fps, size)\n",
        "        for k in range(len(img_array)):\n",
        "          out.write(img_array[k])\n",
        "        out.release()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cTlLYJ0xnlgh",
        "outputId": "1fad43c5-419d-4841-9abb-643f0daef9e2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "file num 1 fadg0\n",
            "file num 2 fcft0\n",
            "file num 3 faks0\n",
            "file num 4 fcmh0\n",
            "file num 5 fcmr0\n",
            "file num 6 fdac1\n",
            "file num 7 fdrd1\n",
            "file num 8 fdms0\n",
            "file num 9 fjas0\n",
            "file num 10 felc0\n",
            "file num 11 fedw0\n",
            "file num 12 fjem0\n",
            "file num 13 fgjd0\n",
            "file num 14 fjre0\n",
            "file num 15 fjwb0\n",
            "file num 16 fpkt0\n",
            "file num 17 fram1\n",
            "file num 18 fkms0\n",
            "file num 19 fcrh0\n",
            "file num 20 mabw0\n",
            "file num 21 mdbb0\n",
            "file num 22 mdld0\n",
            "file num 23 mdab0\n",
            "file num 24 mgwt0\n",
            "file num 25 mcem0\n",
            "file num 26 mccs0\n",
            "file num 27 mbjk0\n",
            "file num 28 mbdg0\n",
            "file num 29 mjar0\n",
            "file num 30 mjsw0\n",
            "file num 31 mmdb1\n",
            "file num 32 mmdm2\n",
            "file num 33 mpdf0\n",
            "file num 34 mpgl0\n",
            "file num 35 mwbt0\n",
            "file num 36 mtmr0\n",
            "file num 37 mtas1\n",
            "file num 38 mstk0\n",
            "file num 39 msjs1\n",
            "file num 40 mrgg0\n",
            "file num 41 mrjo0\n",
            "file num 42 mreb0\n",
            "file num 43 mrcz0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "d=os.listdir('/content/drive/My Drive/vidtimit_videos/non_tampered')\n",
        "len(d)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BdaTkAhgn25J",
        "outputId": "1deb28b0-46f2-4360-db37-2beb164f9c4d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "430"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "c=0\n",
        "for i in data_files:\n",
        "  # i represents user\n",
        "  c=c+1\n",
        "  print('file num',c,i)\n",
        "  files = os.listdir('/content/drive/My Drive/VIDTIMIT/'+i+'/audio')\n",
        "  \n",
        "  for m in range(1,4):\n",
        "    for j in files: \n",
        "      # j represents audio file\n",
        "      \n",
        "      with contextlib.closing(wave.open('/content/drive/My Drive/VIDTIMIT/'+i+'/audio/'+j,'r')) as f:\n",
        "        frames = f.getnframes()\n",
        "        rate = f.getframerate()\n",
        "        duration = frames / float(rate)\n",
        "        \n",
        "        #print(duration)\n",
        "\n",
        "      t = files[m]\n",
        "      if j==t:\n",
        "        t=files[m*2]\n",
        "\n",
        "      if j!=t:\n",
        "        t = t.split('.')[0]\n",
        "        p = '/content/drive/My Drive/VIDTIMIT/'+i+'/video'\n",
        "        if t in os.listdir(p):\n",
        "            temp = os.listdir('/content/drive/My Drive/VIDTIMIT/'+i+'/video/'+t)\n",
        "            frames = len(temp)\n",
        "            fps = frames/duration\n",
        "            img_array = []\n",
        "            for filename in glob.glob('/content/drive/My Drive/VIDTIMIT/'+i+'/video/'+t+'/*'):\n",
        "                img = cv2.imread(filename)\n",
        "                height, width, layers = img.shape\n",
        "                size = (width,height)\n",
        "                img_array.append(img)\n",
        "            n=j.split('.')[0]\n",
        "            out = cv2.VideoWriter('/content/drive/My Drive/vidtimit_videos/tampered/tamp_'+i+'_'+str(m)+'_'+n+'.mp4',cv2.VideoWriter_fourcc(*'DIVX'), fps, size)\n",
        "            for k in range(len(img_array)):\n",
        "              out.write(img_array[k])\n",
        "            out.release()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VF9Mjp4Hn33W",
        "outputId": "1f98eb74-bf4f-4ea8-c878-12c0798988af"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "file num 1 fadg0\n",
            "file num 2 fcft0\n",
            "file num 3 faks0\n",
            "file num 4 fcmh0\n",
            "file num 5 fcmr0\n",
            "file num 6 fdac1\n",
            "file num 7 fdrd1\n",
            "file num 8 fdms0\n",
            "file num 9 fjas0\n",
            "file num 10 felc0\n",
            "file num 11 fedw0\n",
            "file num 12 fjem0\n",
            "file num 13 fgjd0\n",
            "file num 14 fjre0\n",
            "file num 15 fjwb0\n",
            "file num 16 fpkt0\n",
            "file num 17 fram1\n",
            "file num 18 fkms0\n",
            "file num 19 fcrh0\n",
            "file num 20 mabw0\n",
            "file num 21 mdbb0\n",
            "file num 22 mdld0\n",
            "file num 23 mdab0\n",
            "file num 24 mgwt0\n",
            "file num 25 mcem0\n",
            "file num 26 mccs0\n",
            "file num 27 mbjk0\n",
            "file num 28 mbdg0\n",
            "file num 29 mjar0\n",
            "file num 30 mjsw0\n",
            "file num 31 mmdb1\n",
            "file num 32 mmdm2\n",
            "file num 33 mpdf0\n",
            "file num 34 mpgl0\n",
            "file num 35 mwbt0\n",
            "file num 36 mtmr0\n",
            "file num 37 mtas1\n",
            "file num 38 mstk0\n",
            "file num 39 msjs1\n",
            "file num 40 mrgg0\n",
            "file num 41 mrjo0\n",
            "file num 42 mreb0\n",
            "file num 43 mrcz0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "d=os.listdir('/content/drive/My Drive/vidtimit_videos/tampered')\n",
        "len(d)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yHVShIf1n6as",
        "outputId": "cbe52caa-3d53-4170-b164-97ea10e69965"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1287"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# parameters\n",
        "#https://github.com/voletiv/syncnet-in-keras/blob/master/syncnet_params.py\n",
        "\n",
        "MOUTH_H = 112\n",
        "MOUTH_W = 112\n",
        "FACE_H = 224\n",
        "FACE_W = 224\n",
        "MOUTH_TO_FACE_RATIO = 0.65\n",
        "SYNCNET_VIDEO_FPS = 25\n",
        "SYNCNET_VIDEO_CHANNELS = int(0.2 * SYNCNET_VIDEO_FPS)  # 5\n",
        "SYNCNET_MFCC_CHANNELS = 12\n",
        "AUDIO_TIME_STEPS = 20\n",
        "IMAGE_DATA_FORMAT = 'channels_last'"
      ],
      "metadata": {
        "id": "_aqqzb8noWpw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install sk-video"
      ],
      "metadata": {
        "id": "rRBbX6LJoYBJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d9f1f723-6993-41ba-e346-ab2f3d531585"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting sk-video\n",
            "  Downloading sk_video-1.1.10-py2.py3-none-any.whl (2.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.3 MB 7.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from sk-video) (1.7.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from sk-video) (1.21.6)\n",
            "Installing collected packages: sk-video\n",
            "Successfully installed sk-video-1.1.10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        " import skvideo.io"
      ],
      "metadata": {
        "id": "iZZRD3gjtMlo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def make_rect_shape_square(rect):\n",
        "    # Rect: (x, y, x+w, y+h)\n",
        "\n",
        "    x = rect[0]\n",
        "    y = rect[1]\n",
        "    w = rect[2] - x\n",
        "    h = rect[3] - y\n",
        "    # If width > height\n",
        "    if w > h:\n",
        "        new_x = x\n",
        "        new_y = int(y - (w-h)/2)\n",
        "        new_w = w\n",
        "        new_h = w\n",
        "    # Else (height > width)\n",
        "    else:\n",
        "        new_x = int(x - (h-w)/2)\n",
        "        new_y = y\n",
        "        new_w = h\n",
        "        new_h = h\n",
        "    return [new_x, new_y, new_x + new_w, new_y + new_h]\n",
        "\n",
        "\n",
        "def expand_rect(rect, scale, frame_shape, scale_w=1.5, scale_h=1.5):\n",
        "\n",
        "    if scale is not None:\n",
        "        scale_w = scale\n",
        "        scale_h = scale\n",
        "    # Rect: (x, y, x+w, y+h)\n",
        "    x = rect[0]\n",
        "    y = rect[1]\n",
        "    w = rect[2] - x\n",
        "    h = rect[3] - y\n",
        "    # new_w, new_h\n",
        "    new_w = int(w * scale_w)\n",
        "    new_h = int(h * scale_h)\n",
        "    # new_x\n",
        "    new_x = int(x - (new_w - w)/2)\n",
        "    if new_x < 0:\n",
        "        new_w = new_x + new_w\n",
        "        new_x = 0\n",
        "    elif new_x + new_w > (frame_shape[1] - 1):\n",
        "        new_w = (frame_shape[1] - 1) - new_x\n",
        "    # new_y\n",
        "    new_y = int(y - (new_h - h)/2)\n",
        "    if new_y < 0:\n",
        "        new_h = new_y + new_h\n",
        "        new_y = 0\n",
        "    elif new_y + new_h > (frame_shape[0] - 1):\n",
        "        new_h = (frame_shape[0] - 1) - new_y\n",
        "    return [new_x, new_y, new_x + new_w, new_y + new_h]\n",
        "\n",
        "def detect_mouth_in_frame(frame, detector, predictor, prevFace, verbose):\n",
        "    ''' takes frames as input and detect face and mouth from it, then return it with proper coordinates '''\n",
        "\n",
        "    # Detect all faces\n",
        "    faces = detector(frame, 1)\n",
        "\n",
        "    # If no faces are detected\n",
        "    if len(faces) == 0:\n",
        "        if verbose:\n",
        "            print(\"No faces detected, using prevFace\", prevFace, \"(detect_mouth_in_frame)\")\n",
        "        faces = [prevFace]\n",
        "\n",
        "    # Note first face (ASSUMING FIRST FACE IS THE REQUIRED ONE!)\n",
        "    face = faces[0]\n",
        "    # Predict facial landmarks\n",
        "    shape = predictor(frame, face)\n",
        "    # Note all mouth landmark coordinates\n",
        "    mouthCoords = np.array([[shape.part(i).x, shape.part(i).y] for i in range(48, 68)])\n",
        "\n",
        "    # Mouth Rect: x, y, x+w, y+h\n",
        "    mouthRect = [np.min(mouthCoords[:, 1]), np.min(mouthCoords[:, 0]),\n",
        "                 np.max(mouthCoords[:, 1]), np.max(mouthCoords[:, 0])]\n",
        "\n",
        "    # Make mouthRect square\n",
        "    mouthRect = make_rect_shape_square(mouthRect)\n",
        "\n",
        "    # Expand mouthRect square\n",
        "    expandedMouthRect = expand_rect(mouthRect, scale=(MOUTH_TO_FACE_RATIO * face.width() / mouthRect[2]), frame_shape=(frame.shape[0], frame.shape[1]))\n",
        "    \n",
        "    # Mouth\n",
        "    mouth = frame[expandedMouthRect[1]:expandedMouthRect[3],\n",
        "                  expandedMouthRect[0]:expandedMouthRect[2]]\n",
        "\n",
        "    # # Resize to 120x120\n",
        "    # resizedMouthImage = np.round(resize(mouth, (120, 120), preserve_range=True)).astype('uint8')\n",
        "\n",
        "    # Return mouth\n",
        "    return mouth, face"
      ],
      "metadata": {
        "id": "JjC0FhIttMak"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def video_processing(video):\n",
        "  ''' takes video as input and returns array for the detected mouth '''\n",
        "\n",
        "  predictor_path = '/content/drive/My Drive/shape_predictor_68_face_landmarks.dat'\n",
        "  detector = dlib.get_frontal_face_detector()\n",
        "  predictor = dlib.shape_predictor(predictor_path)\n",
        "\n",
        "  cap = cv2.VideoCapture(video)\n",
        "  \n",
        "  # Default face rect\n",
        "  face = dlib.rectangle(30, 30, 220, 220)\n",
        "  lip_model_input = []\n",
        "  frame_index = 0\n",
        "  while(cap.isOpened()):\n",
        "          \n",
        "          frames = []\n",
        "          for i in range(5):\n",
        "              _, frame = cap.read()\n",
        "              frame_index += 1\n",
        "              # print(\"Frame\", frame_index+1, \"of\", frameCount, end=\"\\r\")\n",
        "\n",
        "              # If no frame is read, break\n",
        "              if frame is None:\n",
        "                  break\n",
        "              \n",
        "              # Detect mouth in the frame\n",
        "              mouth, _ = detect_mouth_in_frame(frame, detector, predictor, prevFace=face, verbose=False)\n",
        "\n",
        "              # Convert mouth to grayscale\n",
        "              mouth = cv2.cvtColor(mouth, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "              # Resize mouth to syncnet input shape\n",
        "              mouth = cv2.resize(mouth, (MOUTH_W, MOUTH_H))\n",
        "\n",
        "              # Subtract 110 from all mouth values (Checked in syncnet_demo.m)\n",
        "              mouth = mouth - 110.\n",
        "\n",
        "              frames.append(mouth)\n",
        "\n",
        "          if len(frames) == 5:\n",
        "              stacked = np.stack(frames, axis=-1) #syncnet requires (112,112,5)\n",
        "              lip_model_input.append(stacked)\n",
        "          else:\n",
        "              break\n",
        "\n",
        "  return np.array(lip_model_input)"
      ],
      "metadata": {
        "id": "kFPDfbMUtMQW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# processing frames from live feed\n",
        "\n",
        "def video_process_frames(video):\n",
        "  ''' takes video-frames as input and returns array for the detected mouth '''\n",
        "\n",
        "  predictor_path = '/content/drive/My Drive/shape_predictor_68_face_landmarks.dat'\n",
        "  detector = dlib.get_frontal_face_detector()\n",
        "  predictor = dlib.shape_predictor(predictor_path)\n",
        "\n",
        "  frames_path = '/content/drive/My Drive/VIDTIMIT/faks0/video/sa1'   # passing frames\n",
        "  files = os.listdir(frames_path)\n",
        "  face = dlib.rectangle(30, 30, 220, 220)  # Default face rect\n",
        "  lip_model_input = []\n",
        "  for j in range(0,len(files),5):\n",
        "          frames = []\n",
        "          temp_file=files[j:j+5]\n",
        "          if len(temp_file)==5:\n",
        "            for i in range(5):\n",
        "              \n",
        "              frame = cv2.imread('/content/drive/My Drive/VIDTIMIT/faks0/video/sa1/'+temp_file[i])\n",
        "              \n",
        "              if frame is None:\n",
        "                  break\n",
        "\n",
        "              # Detect mouth in the frame\n",
        "              mouth, _ = detect_mouth_in_frame(frame, detector, predictor, prevFace=face, verbose=False)\n",
        "              # Convert mouth to grayscale\n",
        "              mouth = cv2.cvtColor(mouth, cv2.COLOR_BGR2GRAY)\n",
        "              # Resize mouth to syncnet input shape\n",
        "              mouth = cv2.resize(mouth, (MOUTH_W, MOUTH_H))\n",
        "              # Subtract 110 from all mouth values \n",
        "              mouth = mouth - 110.\n",
        "              frames.append(mouth)\n",
        "\n",
        "          if len(frames) == 5:\n",
        "              stacked = np.stack(frames, axis=-1) #syncnet requires (112,112,5)\n",
        "              lip_model_input.append(stacked)\n",
        "  return np.array(lip_model_input)"
      ],
      "metadata": {
        "id": "UWRUqIKCtMGM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#http://www.practicalcryptography.com/miscellaneous/machine-learning/guide-mel-frequency-cepstral-coefficients-mfccs/\n",
        "\n",
        "def audio_processing(wav_file, verbose):\n",
        "    ''' takes audio file as input and creates mfcc features '''\n",
        "    \n",
        "    \"\"\"To extract mfcc features of audio, clips 0.2 seconds in length each,\n",
        "    i.e. of 20 MFCC features in each clip (acc. to syncnet paper)\n",
        "    Output mfcc_clips shape === (N, 12, 20, 1),\n",
        "    where N = len(mfcc_features) // 20\n",
        "    \"\"\"\n",
        "\n",
        "    rate, sig = wav.read(wav_file)\n",
        "    if verbose:\n",
        "        print(\"Sig length: {}, sample_rate: {}\".format(len(sig), rate))\n",
        "\n",
        "    try:\n",
        "        mfcc_features = speechpy.feature.mfcc(sig, sampling_frequency=rate, frame_length=0.010, frame_stride=0.010)\n",
        "    except IndexError:\n",
        "        raise ValueError(\"ERROR: Index error occurred while extracting mfcc\")\n",
        "\n",
        "    if verbose:\n",
        "        print(\"mfcc_features shape:\", mfcc_features.shape)\n",
        "\n",
        "    # Number of audio clips = len(mfcc_features) // length of each audio clip\n",
        "    number_of_audio_clips = len(mfcc_features) // AUDIO_TIME_STEPS\n",
        "\n",
        "    if verbose:\n",
        "        print(\"Number of audio clips:\", number_of_audio_clips)\n",
        "\n",
        "    # Don't consider the first MFCC feature, only consider the next 12 (Checked in syncnet_demo.m)\n",
        "    # Also, only consider AUDIO_TIME_STEPS*number_of_audio_clips features\n",
        "    mfcc_features = mfcc_features[:AUDIO_TIME_STEPS*number_of_audio_clips, 1:]\n",
        "\n",
        "    # Reshape mfcc_features from (x, 12) to (x//20, 12, 20, 1)\n",
        "    mfcc_features = np.expand_dims(np.transpose(np.split(mfcc_features, number_of_audio_clips), (0, 2, 1)), axis=-1)\n",
        "\n",
        "    if verbose:\n",
        "        print(\"Final mfcc_features shape:\", mfcc_features.shape)\n",
        "    return mfcc_features"
      ],
      "metadata": {
        "id": "tIAyGuAvtL6S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def syncnet_lip_model_v4():\n",
        "    ''' model layers for lip area from video ''' \n",
        "\n",
        "    # Image data format\n",
        "    K.set_image_data_format(IMAGE_DATA_FORMAT)\n",
        "    input_shape = ( MOUTH_H, MOUTH_W, SYNCNET_VIDEO_CHANNELS)\n",
        "\n",
        "    lip_model = Sequential()     # ( None, 112, 112, 5)\n",
        "\n",
        "    # conv1_lip\n",
        "    lip_model.add(Conv2D(96, (3, 3), padding='valid', input_shape=input_shape, name='conv1_lip'))  # (None, 110, 110, 96)\n",
        "    # bn1_lip\n",
        "    lip_model.add(BatchNormalization(name='bn1_lip'))\n",
        "    # relu1_lip\n",
        "    lip_model.add(Activation('relu', name='relu1_lip'))\n",
        "    # pool1_lip\n",
        "    lip_model.add(MaxPooling2D(pool_size=(3, 3), strides=(2, 2), padding='valid', name='pool1_lip'))   # (None, 54, 54, 96)\n",
        "\n",
        "\n",
        "    # conv2_lip\n",
        "    lip_model.add(Conv2D(256, (5, 5), padding='valid', name='conv2_lip'))   # (None, 256, 50, 50)\n",
        "    # bn2_lip\n",
        "    lip_model.add(BatchNormalization(name='bn2_lip'))\n",
        "    # relu2_lip\n",
        "    lip_model.add(Activation('relu', name='relu2_lip'))\n",
        "    # pool2_lip\n",
        "    lip_model.add(MaxPooling2D(pool_size=(3, 3), strides=(2, 2), padding='valid', name='pool2_lip'))   # (None, 24, 24, 256)\n",
        "\n",
        "\n",
        "    # conv3_lip\n",
        "    lip_model.add(Conv2D(512, (3, 3), padding='valid', name='conv3_lip'))   # (None, 22, 22, 512)\n",
        "    # bn3_lip\n",
        "    lip_model.add(BatchNormalization(name='bn3_lip'))\n",
        "    # relu3_lip\n",
        "    lip_model.add(Activation('relu', name='relu3_lip'))\n",
        "\n",
        "\n",
        "    # conv4_lip\n",
        "    lip_model.add(Conv2D(512, (3, 3), padding='valid', name='conv4_lip'))   # (None, 20, 20, 512)\n",
        "    # bn4_lip\n",
        "    lip_model.add(BatchNormalization(name='bn4_lip'))\n",
        "    # relu4_lip\n",
        "    lip_model.add(Activation('relu', name='relu4_lip'))\n",
        "\n",
        "\n",
        "    # conv5_lip\n",
        "    lip_model.add(Conv2D(512, (3, 3), padding='valid', name='conv5_lip'))   # (None, 18, 18, 512)\n",
        "    # bn5_lip\n",
        "    lip_model.add(BatchNormalization(name='bn5_lip'))\n",
        "    # relu5_lip\n",
        "    lip_model.add(Activation('relu', name='relu5_lip'))\n",
        "    # pool5_lip\n",
        "    lip_model.add(MaxPooling2D(pool_size=(3, 3), strides=(3, 3), padding='valid', name='pool5_lip'))   # (None, 6, 6, 512)\n",
        "\n",
        "\n",
        "    # fc6_lip\n",
        "    lip_model.add(Flatten(name='flatten_lip'))\n",
        "    lip_model.add(Dense(256, name='fc6_lip'))    # (None, 256)\n",
        "    # bn6_lip\n",
        "    lip_model.add(BatchNormalization(name='bn6_lip'))\n",
        "    # relu6_lip\n",
        "    lip_model.add(Activation('relu', name='relu6_lip'))\n",
        "\n",
        "\n",
        "    # fc7_lip\n",
        "    lip_model.add(Dense(128, name='fc7_lip'))    # (None, 128)\n",
        "    # bn7_lip\n",
        "    lip_model.add(BatchNormalization(name='bn7_lip'))\n",
        "    # relu7_lip\n",
        "    lip_model.add(Activation('relu', name='relu7_lip'))\n",
        "\n",
        "\n",
        "    return lip_model"
      ],
      "metadata": {
        "id": "j8pZNYebtLs9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def syncnet_audio_model_v4():\n",
        "    ''' model layers for audio features '''\n",
        "\n",
        "    # Audio input shape\n",
        "    input_shape = ( SYNCNET_MFCC_CHANNELS, AUDIO_TIME_STEPS, 1)\n",
        "\n",
        "    audio_model = Sequential()     # (None, 12, 20, 1)\n",
        "\n",
        "    # conv1_audio\n",
        "    audio_model.add(Conv2D(64, (3, 3), padding='same', name='conv1_audio', input_shape=input_shape))  # (None, 12, 20, 64)\n",
        "    # bn1_audio\n",
        "    audio_model.add(BatchNormalization(name='bn1_audio'))\n",
        "    # relu1_audio\n",
        "    audio_model.add(Activation('relu', name='relu1_audio'))\n",
        "\n",
        "\n",
        "    # conv2_audio\n",
        "    audio_model.add(Conv2D(128, (3, 3), padding='same', name='conv2_audio'))   # (None, 12, 20, 128)\n",
        "    # bn2_audio\n",
        "    audio_model.add(BatchNormalization(name='bn2_audio'))\n",
        "    # relu2_audio\n",
        "    audio_model.add(Activation('relu', name='relu2_audio'))\n",
        "    # pool2_audio\n",
        "    audio_model.add(MaxPooling2D(pool_size=(1, 3), strides=(1, 2), padding='valid', name='pool2_audio'))   # (None, 12, 9, 128)\n",
        "\n",
        "\n",
        "    # conv3_audio\n",
        "    audio_model.add(Conv2D(256, (3, 3), padding='same', name='conv3_audio'))   # (None, 12, 9, 256)\n",
        "    # bn3_audio\n",
        "    audio_model.add(BatchNormalization(name='bn3_audio'))\n",
        "    # relu3_audio\n",
        "    audio_model.add(Activation('relu', name='relu3_audio'))\n",
        "\n",
        "\n",
        "    # conv4_audio\n",
        "    audio_model.add(Conv2D(256, (3, 3), padding='same', name='conv4_audio'))   # (None, 12, 9, 256)\n",
        "    # bn4_audio\n",
        "    audio_model.add(BatchNormalization(name='bn4_audio'))\n",
        "    # relu4_audio\n",
        "    audio_model.add(Activation('relu', name='relu4_audio'))\n",
        "\n",
        "\n",
        "    # conv5_audio\n",
        "    audio_model.add(Conv2D(256, (3, 3), padding='same', name='conv5_audio'))   # (None, 12, 9, 256)\n",
        "    # bn5_audio\n",
        "    audio_model.add(BatchNormalization(name='bn5_audio'))\n",
        "    # relu5_audio\n",
        "    audio_model.add(Activation('relu', name='relu5_audio'))\n",
        "    # pool5_audio\n",
        "    audio_model.add(MaxPooling2D(pool_size=(3, 3), strides=(2, 2), padding='valid', name='pool5_audio'))   # (None, 5, 4, 256)\n",
        "\n",
        "\n",
        "    # fc6_audio\n",
        "    audio_model.add(Flatten(name='flatten_audio'))\n",
        "    audio_model.add(Dense(256, name='fc6_audio'))    # (None, 256)\n",
        "    # bn6_audio\n",
        "    audio_model.add(BatchNormalization(name='bn6_audio'))\n",
        "    # relu6_audio\n",
        "    audio_model.add(Activation('relu', name='relu6_audio'))\n",
        "\n",
        "\n",
        "    # fc7_audio\n",
        "    audio_model.add(Dense(128, name='fc7_audio'))    # (None, 128)\n",
        "    # bn7_audio\n",
        "    audio_model.add(BatchNormalization(name='bn7_audio'))\n",
        "    # relu7_audio\n",
        "    audio_model.add(Activation('relu', name='relu7_audio'))\n",
        "\n",
        "\n",
        "    return audio_model"
      ],
      "metadata": {
        "id": "YCSM0a8qtLid"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_syncnet_model(mode, verbose):\n",
        "    ''' loading the syncnet model '''\n",
        "    \n",
        "    if mode == 'lip' or mode == 'both':\n",
        "      # Load frontal model\n",
        "      syncnet_lip_model = syncnet_lip_model_v4()\n",
        "\n",
        "    if mode == 'audio' or mode == 'both':   \n",
        "      # Load frontal model\n",
        "      syncnet_audio_model = syncnet_audio_model_v4()\n",
        "       \n",
        "    if mode == 'lip':\n",
        "        syncnet_model = syncnet_lip_model\n",
        "    elif mode == 'audio':\n",
        "        syncnet_model = syncnet_audio_model\n",
        "    elif mode == 'both':\n",
        "        syncnet_model = [syncnet_audio_model, syncnet_lip_model]\n",
        "\n",
        "    return syncnet_model"
      ],
      "metadata": {
        "id": "e-ZBMm2ZtLW7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# https://github.com/voletiv/syncnet-in-keras/blob/master/syncnet-weights/syncnet-weights-readme.md\n",
        "\n",
        "def load_syncnet_weights( verbose):\n",
        "    ''' reading and loading pre trained weights file '''\n",
        "\n",
        "    syncnet_weights_file = '/content/drive/My Drive/lipsync_v4_73.mat'\n",
        "\n",
        "    if verbose:\n",
        "        print(\"Loading syncnet_weights from\", syncnet_weights_file)\n",
        "\n",
        "    if not os.path.isfile(syncnet_weights_file):\n",
        "        raise ValueError(\n",
        "            \"\\n\\nERROR: syncnet_weight_file missing!! File: \" + syncnet_weights_file + \\\n",
        "            \"\\nPlease specify correct file name .\\n\")\n",
        "\n",
        "    # Read weights file, with layer names\n",
        "    with h5py.File(syncnet_weights_file, 'r') as f:\n",
        "        syncnet_weights = [f[v[0]][:] for v in f['net/params/value']]\n",
        "        syncnet_layer_names = [[chr(i) for i in  f[n[0]]] \\\n",
        "                               for n in f['net/layers/name']]\n",
        "\n",
        "    # Find the starting index of audio and lip layers\n",
        "    audio_found = False\n",
        "    audio_start_idx = 0\n",
        "    lip_found = False\n",
        "    lip_start_idx = 0\n",
        "\n",
        "    # Join the chars of layer names to make them words\n",
        "    for i in range(len(syncnet_layer_names)):\n",
        "        syncnet_layer_names[i] = ''.join(syncnet_layer_names[i])\n",
        "\n",
        "        # Finding audio_start_idx\n",
        "        if not audio_found and 'audio' in syncnet_layer_names[i]:\n",
        "            audio_found = True\n",
        "            if verbose:\n",
        "                print(\"Found audio\")\n",
        "        elif not audio_found and 'audio' not in syncnet_layer_names[i]:\n",
        "            if 'conv' in syncnet_layer_names[i]:\n",
        "                audio_start_idx += 2\n",
        "            elif 'bn' in syncnet_layer_names[i]:\n",
        "                audio_start_idx += 3\n",
        "            elif 'fc' in syncnet_layer_names[i]:\n",
        "                audio_start_idx += 2\n",
        "\n",
        "        # Finding lip_start_idx\n",
        "        if not lip_found and 'lip' in syncnet_layer_names[i]:\n",
        "            lip_found = True\n",
        "            if verbose:\n",
        "                print(\"Found lip\")\n",
        "        elif not lip_found and 'lip' not in syncnet_layer_names[i]:\n",
        "            if 'conv' in syncnet_layer_names[i]:\n",
        "                lip_start_idx += 2\n",
        "            elif 'bn' in syncnet_layer_names[i]:\n",
        "                lip_start_idx += 3\n",
        "            elif 'fc' in syncnet_layer_names[i]:\n",
        "                lip_start_idx += 2\n",
        "\n",
        "        if verbose:\n",
        "            print(\"  \", i, syncnet_layer_names[i])\n",
        "\n",
        "    if verbose:\n",
        "        print(\"  lip_start_idx =\", lip_start_idx)\n",
        "        print(\"  audio_start_idx =\", audio_start_idx)\n",
        "\n",
        "    return syncnet_weights, syncnet_layer_names, audio_start_idx, lip_start_idx"
      ],
      "metadata": {
        "id": "NpWA5zqutLKT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def set_syncnet_weights_to_syncnet_model(syncnet_model, syncnet_weights, syncnet_layer_names, mode, verbose):\n",
        "    ''' loading pre trained weights into the syncnet model layers '''\n",
        "\n",
        "    if verbose:\n",
        "        print(\"Setting weights to model\")\n",
        "\n",
        "    # Video syncnet-related weights begin at 35 in syncnet_weights\n",
        "    if mode == 'lip':\n",
        "        syncnet_weights_idx = 35\n",
        "    else:\n",
        "        syncnet_weights_idx = 0\n",
        "\n",
        "    if mode == 'both':\n",
        "        syncnet_lip_model = syncnet_model[0]\n",
        "        syncnet_audio_model = syncnet_model[1]\n",
        "\n",
        "    # Init syncnet_layer_idx, to be incremented only at 'lip' layers\n",
        "    syncnet_layer_idx = -1\n",
        "\n",
        "    # Load weights layer-by-layer\n",
        "    for i in syncnet_layer_names:\n",
        "\n",
        "        # Skip the irrelevant layers\n",
        "        if mode == 'lip' and 'lip' not in i:\n",
        "            continue\n",
        "        elif mode == 'audio' and 'audio' not in i:\n",
        "            continue\n",
        "\n",
        "        # Increment the index on the model\n",
        "        syncnet_layer_idx += 1\n",
        "\n",
        "        if verbose:\n",
        "            print(\"  SyncNet Layer\", syncnet_layer_idx, \":\", i, \"; weight index :\", syncnet_weights_idx)\n",
        "\n",
        "        # Convolutional layer\n",
        "        if 'conv' in i:\n",
        "            syncnet_model.layers[syncnet_layer_idx].set_weights(\n",
        "                [np.transpose(syncnet_weights[syncnet_weights_idx], (2, 3, 1, 0)),\n",
        "                 np.squeeze(syncnet_weights[syncnet_weights_idx + 1])])\n",
        "            syncnet_weights_idx += 2\n",
        "\n",
        "        # Batch Normalization layer\n",
        "        elif 'bn' in i:\n",
        "            syncnet_model.layers[syncnet_layer_idx].set_weights(\n",
        "                [np.squeeze(syncnet_weights[syncnet_weights_idx]),\n",
        "                 np.squeeze(syncnet_weights[syncnet_weights_idx + 1]),\n",
        "                 syncnet_weights[syncnet_weights_idx + 2][0],\n",
        "                 syncnet_weights[syncnet_weights_idx + 2][1]])\n",
        "            syncnet_weights_idx += 3\n",
        "\n",
        "        # ReLU layer\n",
        "        elif 'relu' in i:\n",
        "            continue\n",
        "\n",
        "        # Pooling layer\n",
        "        elif 'pool' in i:\n",
        "            continue\n",
        "\n",
        "        # Dense (fc) layer\n",
        "        elif 'fc' in i:\n",
        "            # Skip Flatten layer\n",
        "            if 'flatten' in syncnet_model.layers[syncnet_layer_idx].name:\n",
        "                syncnet_layer_idx += 1\n",
        "            # Set weight to Dense layer\n",
        "            syncnet_model.layers[syncnet_layer_idx].set_weights(\n",
        "                [np.reshape(\n",
        "                    np.transpose(syncnet_weights[syncnet_weights_idx],\n",
        "                        (2, 3, 1, 0)),\n",
        "                    (syncnet_weights[syncnet_weights_idx].shape[2]*\\\n",
        "                     syncnet_weights[syncnet_weights_idx].shape[3]*\\\n",
        "                     syncnet_weights[syncnet_weights_idx].shape[1],\n",
        "                     syncnet_weights[syncnet_weights_idx].shape[0])),\n",
        "                np.squeeze(syncnet_weights[syncnet_weights_idx + 1])])\n",
        "            syncnet_weights_idx += 2"
      ],
      "metadata": {
        "id": "PzJ3KkMetK_x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_pretrained_syncnet_model(mode, verbose):\n",
        "    ''' final function to call loading functions here and prepare the final model'''\n",
        "\n",
        "    # mode = {lip, audio, both}\n",
        "    if mode not in {'lip', 'audio', 'both'}:\n",
        "        print(\"\\n\\nERROR: 'mode' not defined properly! Expected one of {'lip', 'audio', 'both'}, got:\", mode, \"\\n\")\n",
        "        return\n",
        "\n",
        "    try:\n",
        "\n",
        "        # Load syncnet model\n",
        "        syncnet_model = load_syncnet_model(mode=mode, verbose=verbose)\n",
        "\n",
        "        if verbose:\n",
        "            print(\"Loaded syncnet model\")\n",
        "\n",
        "        # Read weights and layer names\n",
        "        syncnet_weights, syncnet_layer_names, audio_start_idx, lip_start_idx = load_syncnet_weights(verbose=verbose)\n",
        "\n",
        "        if verbose:\n",
        "            print(\"Loaded syncnet weights.\")\n",
        "\n",
        "        # Set lip weights to syncnet_model\n",
        "        if mode != 'both':\n",
        "            set_syncnet_weights_to_syncnet_model(syncnet_model=syncnet_model,\n",
        "                                                 syncnet_weights=syncnet_weights,\n",
        "                                                 syncnet_layer_names=syncnet_layer_names,\n",
        "                                                 mode=mode,\n",
        "                                                 verbose=verbose)\n",
        "        else:\n",
        "            # Audio\n",
        "            set_syncnet_weights_to_syncnet_model(syncnet_model=syncnet_model[0],\n",
        "                                                 syncnet_weights=syncnet_weights,\n",
        "                                                 syncnet_layer_names=syncnet_layer_names,\n",
        "                                                 mode='audio',\n",
        "                                                 verbose=verbose)\n",
        "            # Lip\n",
        "            set_syncnet_weights_to_syncnet_model(syncnet_model=syncnet_model[1],\n",
        "                                                 syncnet_weights=syncnet_weights,\n",
        "                                                 syncnet_layer_names=syncnet_layer_names,\n",
        "                                                 mode='lip',\n",
        "                                                 verbose=verbose)\n",
        "\n",
        "        if verbose:\n",
        "            print(\"Set syncnet weights.\")\n",
        "\n",
        "    except ValueError as err:\n",
        "        print(err)\n",
        "        return\n",
        "\n",
        "    except KeyboardInterrupt:\n",
        "        print(\"\\n\\nCtrl+C was pressed!\\n\")\n",
        "        return\n",
        "\n",
        "    return syncnet_model"
      ],
      "metadata": {
        "id": "UEgTkNe7tK1z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# calling function to load model with weights\n",
        "\n",
        "mode = 'both'\n",
        "model=load_pretrained_syncnet_model( mode=mode, verbose=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rz47kf15tKof",
        "outputId": "0a1299de-55bf-425a-8d3d-c4b661426650"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded syncnet model\n",
            "Loading syncnet_weights from /content/drive/My Drive/lipsync_v4_73.mat\n",
            "Found audio\n",
            "   0 conv1_audio\n",
            "   1 bn1_audio\n",
            "   2 relu1_audio\n",
            "   3 conv2_audio\n",
            "   4 bn2_audio\n",
            "   5 relu2_audio\n",
            "   6 pool2_audio\n",
            "   7 conv3_audio\n",
            "   8 bn3_audio\n",
            "   9 relu3_audio\n",
            "   10 conv4_audio\n",
            "   11 bn4_audio\n",
            "   12 relu4_audio\n",
            "   13 conv5_audio\n",
            "   14 bn5_audio\n",
            "   15 relu5_audio\n",
            "   16 pool5_audio\n",
            "   17 fc6_audio\n",
            "   18 bn6_audio\n",
            "   19 relu6_audio\n",
            "   20 fc7_audio\n",
            "   21 bn7_audio\n",
            "   22 relu7_audio\n",
            "Found lip\n",
            "   23 conv1_lip\n",
            "   24 bn1_lip\n",
            "   25 relu1_lip\n",
            "   26 pool1_lip\n",
            "   27 conv2_lip\n",
            "   28 bn2_lip\n",
            "   29 relu2_lip\n",
            "   30 pool2_lip\n",
            "   31 conv3_lip\n",
            "   32 bn3_lip\n",
            "   33 relu3_lip\n",
            "   34 conv4_lip\n",
            "   35 bn4_lip\n",
            "   36 relu4_lip\n",
            "   37 conv5_lip\n",
            "   38 bn5_lip\n",
            "   39 relu5_lip\n",
            "   40 pool5_lip\n",
            "   41 fc6_lip\n",
            "   42 bn6_lip\n",
            "   43 relu6_lip\n",
            "   44 fc7_lip\n",
            "   45 bn7_lip\n",
            "   46 relu7_lip\n",
            "   47 dist\n",
            "   48 loss\n",
            "  lip_start_idx = 35\n",
            "  audio_start_idx = 0\n",
            "Loaded syncnet weights.\n",
            "Setting weights to model\n",
            "  SyncNet Layer 0 : conv1_audio ; weight index : 0\n",
            "  SyncNet Layer 1 : bn1_audio ; weight index : 2\n",
            "  SyncNet Layer 2 : relu1_audio ; weight index : 5\n",
            "  SyncNet Layer 3 : conv2_audio ; weight index : 5\n",
            "  SyncNet Layer 4 : bn2_audio ; weight index : 7\n",
            "  SyncNet Layer 5 : relu2_audio ; weight index : 10\n",
            "  SyncNet Layer 6 : pool2_audio ; weight index : 10\n",
            "  SyncNet Layer 7 : conv3_audio ; weight index : 10\n",
            "  SyncNet Layer 8 : bn3_audio ; weight index : 12\n",
            "  SyncNet Layer 9 : relu3_audio ; weight index : 15\n",
            "  SyncNet Layer 10 : conv4_audio ; weight index : 15\n",
            "  SyncNet Layer 11 : bn4_audio ; weight index : 17\n",
            "  SyncNet Layer 12 : relu4_audio ; weight index : 20\n",
            "  SyncNet Layer 13 : conv5_audio ; weight index : 20\n",
            "  SyncNet Layer 14 : bn5_audio ; weight index : 22\n",
            "  SyncNet Layer 15 : relu5_audio ; weight index : 25\n",
            "  SyncNet Layer 16 : pool5_audio ; weight index : 25\n",
            "  SyncNet Layer 17 : fc6_audio ; weight index : 25\n",
            "  SyncNet Layer 19 : bn6_audio ; weight index : 27\n",
            "  SyncNet Layer 20 : relu6_audio ; weight index : 30\n",
            "  SyncNet Layer 21 : fc7_audio ; weight index : 30\n",
            "  SyncNet Layer 22 : bn7_audio ; weight index : 32\n",
            "  SyncNet Layer 23 : relu7_audio ; weight index : 35\n",
            "Setting weights to model\n",
            "  SyncNet Layer 0 : conv1_lip ; weight index : 35\n",
            "  SyncNet Layer 1 : bn1_lip ; weight index : 37\n",
            "  SyncNet Layer 2 : relu1_lip ; weight index : 40\n",
            "  SyncNet Layer 3 : pool1_lip ; weight index : 40\n",
            "  SyncNet Layer 4 : conv2_lip ; weight index : 40\n",
            "  SyncNet Layer 5 : bn2_lip ; weight index : 42\n",
            "  SyncNet Layer 6 : relu2_lip ; weight index : 45\n",
            "  SyncNet Layer 7 : pool2_lip ; weight index : 45\n",
            "  SyncNet Layer 8 : conv3_lip ; weight index : 45\n",
            "  SyncNet Layer 9 : bn3_lip ; weight index : 47\n",
            "  SyncNet Layer 10 : relu3_lip ; weight index : 50\n",
            "  SyncNet Layer 11 : conv4_lip ; weight index : 50\n",
            "  SyncNet Layer 12 : bn4_lip ; weight index : 52\n",
            "  SyncNet Layer 13 : relu4_lip ; weight index : 55\n",
            "  SyncNet Layer 14 : conv5_lip ; weight index : 55\n",
            "  SyncNet Layer 15 : bn5_lip ; weight index : 57\n",
            "  SyncNet Layer 16 : relu5_lip ; weight index : 60\n",
            "  SyncNet Layer 17 : pool5_lip ; weight index : 60\n",
            "  SyncNet Layer 18 : fc6_lip ; weight index : 60\n",
            "  SyncNet Layer 20 : bn6_lip ; weight index : 62\n",
            "  SyncNet Layer 21 : relu6_lip ; weight index : 65\n",
            "  SyncNet Layer 22 : fc7_lip ; weight index : 65\n",
            "  SyncNet Layer 23 : bn7_lip ; weight index : 67\n",
            "  SyncNet Layer 24 : relu7_lip ; weight index : 70\n",
            "Set syncnet weights.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model"
      ],
      "metadata": {
        "id": "CvwmNd8CtKfm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "29995ca7-7328-40a0-e4cb-28420d1d63a7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<keras.engine.sequential.Sequential at 0x7fcf001b8450>,\n",
              " <keras.engine.sequential.Sequential at 0x7fcf00214210>]"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model[0].summary()"
      ],
      "metadata": {
        "id": "xAek1awitKTn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7f7bb8d9-fec5-43ec-c491-6f642060c31e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv1_audio (Conv2D)        (None, 12, 20, 64)        640       \n",
            "                                                                 \n",
            " bn1_audio (BatchNormalizati  (None, 12, 20, 64)       256       \n",
            " on)                                                             \n",
            "                                                                 \n",
            " relu1_audio (Activation)    (None, 12, 20, 64)        0         \n",
            "                                                                 \n",
            " conv2_audio (Conv2D)        (None, 12, 20, 128)       73856     \n",
            "                                                                 \n",
            " bn2_audio (BatchNormalizati  (None, 12, 20, 128)      512       \n",
            " on)                                                             \n",
            "                                                                 \n",
            " relu2_audio (Activation)    (None, 12, 20, 128)       0         \n",
            "                                                                 \n",
            " pool2_audio (MaxPooling2D)  (None, 12, 9, 128)        0         \n",
            "                                                                 \n",
            " conv3_audio (Conv2D)        (None, 12, 9, 256)        295168    \n",
            "                                                                 \n",
            " bn3_audio (BatchNormalizati  (None, 12, 9, 256)       1024      \n",
            " on)                                                             \n",
            "                                                                 \n",
            " relu3_audio (Activation)    (None, 12, 9, 256)        0         \n",
            "                                                                 \n",
            " conv4_audio (Conv2D)        (None, 12, 9, 256)        590080    \n",
            "                                                                 \n",
            " bn4_audio (BatchNormalizati  (None, 12, 9, 256)       1024      \n",
            " on)                                                             \n",
            "                                                                 \n",
            " relu4_audio (Activation)    (None, 12, 9, 256)        0         \n",
            "                                                                 \n",
            " conv5_audio (Conv2D)        (None, 12, 9, 256)        590080    \n",
            "                                                                 \n",
            " bn5_audio (BatchNormalizati  (None, 12, 9, 256)       1024      \n",
            " on)                                                             \n",
            "                                                                 \n",
            " relu5_audio (Activation)    (None, 12, 9, 256)        0         \n",
            "                                                                 \n",
            " pool5_audio (MaxPooling2D)  (None, 5, 4, 256)         0         \n",
            "                                                                 \n",
            " flatten_audio (Flatten)     (None, 5120)              0         \n",
            "                                                                 \n",
            " fc6_audio (Dense)           (None, 256)               1310976   \n",
            "                                                                 \n",
            " bn6_audio (BatchNormalizati  (None, 256)              1024      \n",
            " on)                                                             \n",
            "                                                                 \n",
            " relu6_audio (Activation)    (None, 256)               0         \n",
            "                                                                 \n",
            " fc7_audio (Dense)           (None, 128)               32896     \n",
            "                                                                 \n",
            " bn7_audio (BatchNormalizati  (None, 128)              512       \n",
            " on)                                                             \n",
            "                                                                 \n",
            " relu7_audio (Activation)    (None, 128)               0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2,899,072\n",
            "Trainable params: 2,896,384\n",
            "Non-trainable params: 2,688\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model[1].summary()"
      ],
      "metadata": {
        "id": "oAivw40xtKLZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "844751e5-8261-4831-f37c-544f3782e0ef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv1_lip (Conv2D)          (None, 110, 110, 96)      4416      \n",
            "                                                                 \n",
            " bn1_lip (BatchNormalization  (None, 110, 110, 96)     384       \n",
            " )                                                               \n",
            "                                                                 \n",
            " relu1_lip (Activation)      (None, 110, 110, 96)      0         \n",
            "                                                                 \n",
            " pool1_lip (MaxPooling2D)    (None, 54, 54, 96)        0         \n",
            "                                                                 \n",
            " conv2_lip (Conv2D)          (None, 50, 50, 256)       614656    \n",
            "                                                                 \n",
            " bn2_lip (BatchNormalization  (None, 50, 50, 256)      1024      \n",
            " )                                                               \n",
            "                                                                 \n",
            " relu2_lip (Activation)      (None, 50, 50, 256)       0         \n",
            "                                                                 \n",
            " pool2_lip (MaxPooling2D)    (None, 24, 24, 256)       0         \n",
            "                                                                 \n",
            " conv3_lip (Conv2D)          (None, 22, 22, 512)       1180160   \n",
            "                                                                 \n",
            " bn3_lip (BatchNormalization  (None, 22, 22, 512)      2048      \n",
            " )                                                               \n",
            "                                                                 \n",
            " relu3_lip (Activation)      (None, 22, 22, 512)       0         \n",
            "                                                                 \n",
            " conv4_lip (Conv2D)          (None, 20, 20, 512)       2359808   \n",
            "                                                                 \n",
            " bn4_lip (BatchNormalization  (None, 20, 20, 512)      2048      \n",
            " )                                                               \n",
            "                                                                 \n",
            " relu4_lip (Activation)      (None, 20, 20, 512)       0         \n",
            "                                                                 \n",
            " conv5_lip (Conv2D)          (None, 18, 18, 512)       2359808   \n",
            "                                                                 \n",
            " bn5_lip (BatchNormalization  (None, 18, 18, 512)      2048      \n",
            " )                                                               \n",
            "                                                                 \n",
            " relu5_lip (Activation)      (None, 18, 18, 512)       0         \n",
            "                                                                 \n",
            " pool5_lip (MaxPooling2D)    (None, 6, 6, 512)         0         \n",
            "                                                                 \n",
            " flatten_lip (Flatten)       (None, 18432)             0         \n",
            "                                                                 \n",
            " fc6_lip (Dense)             (None, 256)               4718848   \n",
            "                                                                 \n",
            " bn6_lip (BatchNormalization  (None, 256)              1024      \n",
            " )                                                               \n",
            "                                                                 \n",
            " relu6_lip (Activation)      (None, 256)               0         \n",
            "                                                                 \n",
            " fc7_lip (Dense)             (None, 128)               32896     \n",
            "                                                                 \n",
            " bn7_lip (BatchNormalization  (None, 128)              512       \n",
            " )                                                               \n",
            "                                                                 \n",
            " relu7_lip (Activation)      (None, 128)               0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 11,279,680\n",
            "Trainable params: 11,275,136\n",
            "Non-trainable params: 4,544\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# for evaluation calculating euclidian distance in numpy\n",
        "\n",
        "def euclidian_distance(data_1, data_2): \n",
        "    dist = np.sqrt( np.sum(np.square(data_1 - data_2), axis=-1) )\n",
        "    return dist\n",
        "\n",
        "def distance_euc(feat1,feat2,vshift):\n",
        "  ''' takes 2 arrays as input and return euclidian distance between those '''\n",
        "  \n",
        "  win_size = vshift*2+1\n",
        "  n = np.pad(feat2, vshift, mode='constant')  \n",
        "  feat2p = n[:,:feat2.shape[1]]\n",
        "  #print(feat2p.shape)\n",
        "  \n",
        "  if feat1.shape[0]+win_size != feat2p.shape[0]:\n",
        "    n=abs(feat1.shape[0]+win_size - feat2p.shape[0])\n",
        "    if feat1.shape[0]+win_size<feat2p.shape[0]:\n",
        "      pass\n",
        "    elif feat1.shape[0]+win_size>feat2p.shape[0]:\n",
        "      low = feat2p\n",
        "      high = feat1\n",
        "      for i in range(n):\n",
        "        temp=[0 for j in range(len(feat1[0]))]\n",
        "        low=np.append(low,temp)\n",
        "     # print(low.shape,high.shape)\n",
        "\n",
        "      low.shape=(feat1.shape[0]+win_size,len(feat1[0]))\n",
        "\n",
        "      if low.shape[0]<high.shape[0]:\n",
        "        feat1=low\n",
        "        feat2p=high\n",
        "      elif low.shape[0]>high.shape[0]:\n",
        "        feat1=high\n",
        "        feat2p=low\n",
        "\n",
        "  dists = []\n",
        "  for i in range(0,len(feat1)):\n",
        "    a=feat1[[i],:].repeat(win_size, 1)\n",
        "    a.shape=(win_size,feat1.shape[1])\n",
        "    b=feat2p[i:i+win_size,:]\n",
        "    \n",
        "    dists.append(euclidian_distance(a, b))\n",
        "  return dists\n"
      ],
      "metadata": {
        "id": "QANAGtdEtJ8q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "non_tamp_video_files=os.listdir('/content/drive/My Drive/vidtimit_videos/non_tampered')\n",
        "\n",
        "non_tamp_conf=[]\n",
        "\n",
        "c=0\n",
        "for file in non_tamp_video_files:\n",
        "  c=c+1\n",
        "  video='/content/drive/My Drive/vidtimit_videos/non_tampered/'+file\n",
        "  user=video.split('_')[2]\n",
        "  user=user.split('/')[1]\n",
        "  au=video.split('_')[-1]\n",
        "  au=au.split('.')[0]\n",
        "\n",
        "  video_fea=video_processing(video)\n",
        "  audio_fea=audio_processing('/content/drive/My Drive/VIDTIMIT/'+user+'/audio/'+au+'.wav',False)\n",
        "  \n",
        "\n",
        "  audio_pred = model[0].predict(audio_fea)\n",
        "  #non_tamp_aud_features.append(audio_pred)\n",
        "  lip_pred = model[1].predict(video_fea)\n",
        "  #non_tamp_vid_features.append(lip_pred)\n",
        "\n",
        "  dists = distance_euc(lip_pred, audio_pred, 15)\n",
        "  mdist = np.mean(np.stack(dists,1),1)\n",
        "  conf = np.median(mdist)-min(mdist)\n",
        "  non_tamp_conf.append(conf)\n",
        "  print(c, 'file processed')"
      ],
      "metadata": {
        "id": "D-cq4j7ttJry",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "16e10916-8169-40f7-ee6d-0f88b147cc6b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1 file processed\n",
            "2 file processed\n",
            "3 file processed\n",
            "4 file processed\n",
            "5 file processed\n",
            "6 file processed\n",
            "7 file processed\n",
            "8 file processed\n",
            "9 file processed\n",
            "10 file processed\n",
            "11 file processed\n",
            "12 file processed\n",
            "13 file processed\n",
            "14 file processed\n",
            "15 file processed\n",
            "16 file processed\n",
            "17 file processed\n",
            "18 file processed\n",
            "19 file processed\n",
            "20 file processed\n",
            "21 file processed\n",
            "22 file processed\n",
            "23 file processed\n",
            "24 file processed\n",
            "25 file processed\n",
            "26 file processed\n",
            "27 file processed\n",
            "28 file processed\n",
            "29 file processed\n",
            "30 file processed\n",
            "31 file processed\n",
            "32 file processed\n",
            "33 file processed\n",
            "34 file processed\n",
            "35 file processed\n",
            "36 file processed\n",
            "37 file processed\n",
            "38 file processed\n",
            "39 file processed\n",
            "40 file processed\n",
            "41 file processed\n",
            "42 file processed\n",
            "43 file processed\n",
            "44 file processed\n",
            "45 file processed\n",
            "46 file processed\n",
            "47 file processed\n",
            "48 file processed\n",
            "49 file processed\n",
            "50 file processed\n",
            "51 file processed\n",
            "52 file processed\n",
            "53 file processed\n",
            "54 file processed\n",
            "55 file processed\n",
            "56 file processed\n",
            "57 file processed\n",
            "58 file processed\n",
            "59 file processed\n",
            "60 file processed\n",
            "61 file processed\n",
            "62 file processed\n",
            "63 file processed\n",
            "64 file processed\n",
            "65 file processed\n",
            "66 file processed\n",
            "67 file processed\n",
            "68 file processed\n",
            "69 file processed\n",
            "70 file processed\n",
            "71 file processed\n",
            "72 file processed\n",
            "73 file processed\n",
            "74 file processed\n",
            "75 file processed\n",
            "76 file processed\n",
            "77 file processed\n",
            "78 file processed\n",
            "79 file processed\n",
            "80 file processed\n",
            "81 file processed\n",
            "82 file processed\n",
            "83 file processed\n",
            "84 file processed\n",
            "85 file processed\n",
            "86 file processed\n",
            "87 file processed\n",
            "88 file processed\n",
            "89 file processed\n",
            "90 file processed\n",
            "91 file processed\n",
            "92 file processed\n",
            "93 file processed\n",
            "94 file processed\n",
            "95 file processed\n",
            "96 file processed\n",
            "97 file processed\n",
            "98 file processed\n",
            "99 file processed\n",
            "100 file processed\n",
            "101 file processed\n",
            "102 file processed\n",
            "103 file processed\n",
            "104 file processed\n",
            "105 file processed\n",
            "106 file processed\n",
            "107 file processed\n",
            "108 file processed\n",
            "109 file processed\n",
            "110 file processed\n",
            "111 file processed\n",
            "112 file processed\n",
            "113 file processed\n",
            "114 file processed\n",
            "115 file processed\n",
            "116 file processed\n",
            "117 file processed\n",
            "118 file processed\n",
            "119 file processed\n",
            "120 file processed\n",
            "121 file processed\n",
            "122 file processed\n",
            "123 file processed\n",
            "124 file processed\n",
            "125 file processed\n",
            "126 file processed\n",
            "127 file processed\n",
            "128 file processed\n",
            "129 file processed\n",
            "130 file processed\n",
            "131 file processed\n",
            "132 file processed\n",
            "133 file processed\n",
            "134 file processed\n",
            "135 file processed\n",
            "136 file processed\n",
            "137 file processed\n",
            "138 file processed\n",
            "139 file processed\n",
            "140 file processed\n",
            "141 file processed\n",
            "142 file processed\n",
            "143 file processed\n",
            "144 file processed\n",
            "145 file processed\n",
            "146 file processed\n",
            "147 file processed\n",
            "148 file processed\n",
            "149 file processed\n",
            "150 file processed\n",
            "151 file processed\n",
            "152 file processed\n",
            "153 file processed\n",
            "154 file processed\n",
            "155 file processed\n",
            "156 file processed\n",
            "157 file processed\n",
            "158 file processed\n",
            "159 file processed\n",
            "160 file processed\n",
            "161 file processed\n",
            "162 file processed\n",
            "163 file processed\n",
            "164 file processed\n",
            "165 file processed\n",
            "166 file processed\n",
            "167 file processed\n",
            "168 file processed\n",
            "169 file processed\n",
            "170 file processed\n",
            "171 file processed\n",
            "172 file processed\n",
            "173 file processed\n",
            "174 file processed\n",
            "175 file processed\n",
            "176 file processed\n",
            "177 file processed\n",
            "178 file processed\n",
            "179 file processed\n",
            "180 file processed\n",
            "181 file processed\n",
            "182 file processed\n",
            "183 file processed\n",
            "184 file processed\n",
            "185 file processed\n",
            "186 file processed\n",
            "187 file processed\n",
            "188 file processed\n",
            "189 file processed\n",
            "190 file processed\n",
            "191 file processed\n",
            "192 file processed\n",
            "193 file processed\n",
            "194 file processed\n",
            "195 file processed\n",
            "196 file processed\n",
            "197 file processed\n",
            "198 file processed\n",
            "199 file processed\n",
            "200 file processed\n",
            "201 file processed\n",
            "202 file processed\n",
            "203 file processed\n",
            "204 file processed\n",
            "205 file processed\n",
            "206 file processed\n",
            "207 file processed\n",
            "208 file processed\n",
            "209 file processed\n",
            "210 file processed\n",
            "211 file processed\n",
            "212 file processed\n",
            "213 file processed\n",
            "214 file processed\n",
            "215 file processed\n",
            "216 file processed\n",
            "217 file processed\n",
            "218 file processed\n",
            "219 file processed\n",
            "220 file processed\n",
            "221 file processed\n",
            "222 file processed\n",
            "223 file processed\n",
            "224 file processed\n",
            "225 file processed\n",
            "226 file processed\n",
            "227 file processed\n",
            "228 file processed\n",
            "229 file processed\n",
            "230 file processed\n",
            "231 file processed\n",
            "232 file processed\n",
            "233 file processed\n",
            "234 file processed\n",
            "235 file processed\n",
            "236 file processed\n",
            "237 file processed\n",
            "238 file processed\n",
            "239 file processed\n",
            "240 file processed\n",
            "241 file processed\n",
            "242 file processed\n",
            "243 file processed\n",
            "244 file processed\n",
            "245 file processed\n",
            "246 file processed\n",
            "247 file processed\n",
            "248 file processed\n",
            "249 file processed\n",
            "250 file processed\n",
            "251 file processed\n",
            "252 file processed\n",
            "253 file processed\n",
            "254 file processed\n",
            "255 file processed\n",
            "256 file processed\n",
            "257 file processed\n",
            "258 file processed\n",
            "259 file processed\n",
            "260 file processed\n",
            "261 file processed\n",
            "262 file processed\n",
            "263 file processed\n",
            "264 file processed\n",
            "265 file processed\n",
            "266 file processed\n",
            "267 file processed\n",
            "268 file processed\n",
            "269 file processed\n",
            "270 file processed\n",
            "271 file processed\n",
            "272 file processed\n",
            "273 file processed\n",
            "274 file processed\n",
            "275 file processed\n",
            "276 file processed\n",
            "277 file processed\n",
            "278 file processed\n",
            "279 file processed\n",
            "280 file processed\n",
            "281 file processed\n",
            "282 file processed\n",
            "283 file processed\n",
            "284 file processed\n",
            "285 file processed\n",
            "286 file processed\n",
            "287 file processed\n",
            "288 file processed\n",
            "289 file processed\n",
            "290 file processed\n",
            "291 file processed\n",
            "292 file processed\n",
            "293 file processed\n",
            "294 file processed\n",
            "295 file processed\n",
            "296 file processed\n",
            "297 file processed\n",
            "298 file processed\n",
            "299 file processed\n",
            "300 file processed\n",
            "301 file processed\n",
            "302 file processed\n",
            "303 file processed\n",
            "304 file processed\n",
            "305 file processed\n",
            "306 file processed\n",
            "307 file processed\n",
            "308 file processed\n",
            "309 file processed\n",
            "310 file processed\n",
            "311 file processed\n",
            "312 file processed\n",
            "313 file processed\n",
            "314 file processed\n",
            "315 file processed\n",
            "316 file processed\n",
            "317 file processed\n",
            "318 file processed\n",
            "319 file processed\n",
            "320 file processed\n",
            "321 file processed\n",
            "322 file processed\n",
            "323 file processed\n",
            "324 file processed\n",
            "325 file processed\n",
            "326 file processed\n",
            "327 file processed\n",
            "328 file processed\n",
            "329 file processed\n",
            "330 file processed\n",
            "331 file processed\n",
            "332 file processed\n",
            "333 file processed\n",
            "334 file processed\n",
            "335 file processed\n",
            "336 file processed\n",
            "337 file processed\n",
            "338 file processed\n",
            "339 file processed\n",
            "340 file processed\n",
            "341 file processed\n",
            "342 file processed\n",
            "343 file processed\n",
            "344 file processed\n",
            "345 file processed\n",
            "346 file processed\n",
            "347 file processed\n",
            "348 file processed\n",
            "349 file processed\n",
            "350 file processed\n",
            "351 file processed\n",
            "352 file processed\n",
            "353 file processed\n",
            "354 file processed\n",
            "355 file processed\n",
            "356 file processed\n",
            "357 file processed\n",
            "358 file processed\n",
            "359 file processed\n",
            "360 file processed\n",
            "361 file processed\n",
            "362 file processed\n",
            "363 file processed\n",
            "364 file processed\n",
            "365 file processed\n",
            "366 file processed\n",
            "367 file processed\n",
            "368 file processed\n",
            "369 file processed\n",
            "370 file processed\n",
            "371 file processed\n",
            "372 file processed\n",
            "373 file processed\n",
            "374 file processed\n",
            "375 file processed\n",
            "376 file processed\n",
            "377 file processed\n",
            "378 file processed\n",
            "379 file processed\n",
            "380 file processed\n",
            "381 file processed\n",
            "382 file processed\n",
            "383 file processed\n",
            "384 file processed\n",
            "385 file processed\n",
            "386 file processed\n",
            "387 file processed\n",
            "388 file processed\n",
            "389 file processed\n",
            "390 file processed\n",
            "391 file processed\n",
            "392 file processed\n",
            "393 file processed\n",
            "394 file processed\n",
            "395 file processed\n",
            "396 file processed\n",
            "397 file processed\n",
            "398 file processed\n",
            "399 file processed\n",
            "400 file processed\n",
            "401 file processed\n",
            "402 file processed\n",
            "403 file processed\n",
            "404 file processed\n",
            "405 file processed\n",
            "406 file processed\n",
            "407 file processed\n",
            "408 file processed\n",
            "409 file processed\n",
            "410 file processed\n",
            "411 file processed\n",
            "412 file processed\n",
            "413 file processed\n",
            "414 file processed\n",
            "415 file processed\n",
            "416 file processed\n",
            "417 file processed\n",
            "418 file processed\n",
            "419 file processed\n",
            "420 file processed\n",
            "421 file processed\n",
            "422 file processed\n",
            "423 file processed\n",
            "424 file processed\n",
            "425 file processed\n",
            "426 file processed\n",
            "427 file processed\n",
            "428 file processed\n",
            "429 file processed\n",
            "430 file processed\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.save('/content/drive/My Drive/non_tamp_conf_EucDis',non_tamp_conf)"
      ],
      "metadata": {
        "id": "2S2vM25UtJcq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tamp_video_files=os.listdir('/content/drive/My Drive/vidtimit_videos/tampered')\n",
        "\n",
        "tamp_conf=[]\n",
        "\n",
        "c=0\n",
        "for file in tamp_video_files:\n",
        "  c=c+1\n",
        "  video='/content/drive/My Drive/vidtimit_videos/tampered/'+file\n",
        "  user=video.split('_')[2]\n",
        "  au=video.split('_')[-1]\n",
        "  au=au.split('.')[0]\n",
        "\n",
        "  video_fea=video_processing(video)\n",
        "  audio_fea=audio_processing('/content/drive/My Drive/VIDTIMIT/'+user+'/audio/'+au+'.wav',False)\n",
        "\n",
        "  audio_pred = model[0].predict(audio_fea)\n",
        "  #print(audio_pred.shape)\n",
        "  lip_pred = model[1].predict(video_fea)\n",
        "  #print(lip_pred.shape)\n",
        "  \n",
        "  dists = distance_euc(lip_pred, audio_pred, 15)\n",
        "  mdist = np.mean(np.stack(dists,1),1)\n",
        "  conf=np.median(mdist)-min(mdist)\n",
        "  tamp_conf.append(conf)\n",
        "  print(c, 'file processed')"
      ],
      "metadata": {
        "id": "XcwVcu0QTAeo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "11910405-ab08-40a4-d2cb-c383bce82978"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1 file processed\n",
            "2 file processed\n",
            "3 file processed\n",
            "4 file processed\n",
            "5 file processed\n",
            "6 file processed\n",
            "7 file processed\n",
            "8 file processed\n",
            "9 file processed\n",
            "10 file processed\n",
            "11 file processed\n",
            "12 file processed\n",
            "13 file processed\n",
            "14 file processed\n",
            "15 file processed\n",
            "16 file processed\n",
            "17 file processed\n",
            "18 file processed\n",
            "19 file processed\n",
            "20 file processed\n",
            "21 file processed\n",
            "22 file processed\n",
            "23 file processed\n",
            "24 file processed\n",
            "25 file processed\n",
            "26 file processed\n",
            "27 file processed\n",
            "28 file processed\n",
            "29 file processed\n",
            "30 file processed\n",
            "31 file processed\n",
            "32 file processed\n",
            "33 file processed\n",
            "34 file processed\n",
            "35 file processed\n",
            "36 file processed\n",
            "37 file processed\n",
            "38 file processed\n",
            "39 file processed\n",
            "40 file processed\n",
            "41 file processed\n",
            "42 file processed\n",
            "43 file processed\n",
            "44 file processed\n",
            "45 file processed\n",
            "46 file processed\n",
            "47 file processed\n",
            "48 file processed\n",
            "49 file processed\n",
            "50 file processed\n",
            "51 file processed\n",
            "52 file processed\n",
            "53 file processed\n",
            "54 file processed\n",
            "55 file processed\n",
            "56 file processed\n",
            "57 file processed\n",
            "58 file processed\n",
            "59 file processed\n",
            "60 file processed\n",
            "61 file processed\n",
            "62 file processed\n",
            "63 file processed\n",
            "64 file processed\n",
            "65 file processed\n",
            "66 file processed\n",
            "67 file processed\n",
            "68 file processed\n",
            "69 file processed\n",
            "70 file processed\n",
            "71 file processed\n",
            "72 file processed\n",
            "73 file processed\n",
            "74 file processed\n",
            "75 file processed\n",
            "76 file processed\n",
            "77 file processed\n",
            "78 file processed\n",
            "79 file processed\n",
            "80 file processed\n",
            "81 file processed\n",
            "82 file processed\n",
            "83 file processed\n",
            "84 file processed\n",
            "85 file processed\n",
            "86 file processed\n",
            "87 file processed\n",
            "88 file processed\n",
            "89 file processed\n",
            "90 file processed\n",
            "91 file processed\n",
            "92 file processed\n",
            "93 file processed\n",
            "94 file processed\n",
            "95 file processed\n",
            "96 file processed\n",
            "97 file processed\n",
            "98 file processed\n",
            "99 file processed\n",
            "100 file processed\n",
            "101 file processed\n",
            "102 file processed\n",
            "103 file processed\n",
            "104 file processed\n",
            "105 file processed\n",
            "106 file processed\n",
            "107 file processed\n",
            "108 file processed\n",
            "109 file processed\n",
            "110 file processed\n",
            "111 file processed\n",
            "112 file processed\n",
            "113 file processed\n",
            "114 file processed\n",
            "115 file processed\n",
            "116 file processed\n",
            "117 file processed\n",
            "118 file processed\n",
            "119 file processed\n",
            "120 file processed\n",
            "121 file processed\n",
            "122 file processed\n",
            "123 file processed\n",
            "124 file processed\n",
            "125 file processed\n",
            "126 file processed\n",
            "127 file processed\n",
            "128 file processed\n",
            "129 file processed\n",
            "130 file processed\n",
            "131 file processed\n",
            "132 file processed\n",
            "133 file processed\n",
            "134 file processed\n",
            "135 file processed\n",
            "136 file processed\n",
            "137 file processed\n",
            "138 file processed\n",
            "139 file processed\n",
            "140 file processed\n",
            "141 file processed\n",
            "142 file processed\n",
            "143 file processed\n",
            "144 file processed\n",
            "145 file processed\n",
            "146 file processed\n",
            "147 file processed\n",
            "148 file processed\n",
            "149 file processed\n",
            "150 file processed\n",
            "151 file processed\n",
            "152 file processed\n",
            "153 file processed\n",
            "154 file processed\n",
            "155 file processed\n",
            "156 file processed\n",
            "157 file processed\n",
            "158 file processed\n",
            "159 file processed\n",
            "160 file processed\n",
            "161 file processed\n",
            "162 file processed\n",
            "163 file processed\n",
            "164 file processed\n",
            "165 file processed\n",
            "166 file processed\n",
            "167 file processed\n",
            "168 file processed\n",
            "169 file processed\n",
            "170 file processed\n",
            "171 file processed\n",
            "172 file processed\n",
            "173 file processed\n",
            "174 file processed\n",
            "175 file processed\n",
            "176 file processed\n",
            "177 file processed\n",
            "178 file processed\n",
            "179 file processed\n",
            "180 file processed\n",
            "181 file processed\n",
            "182 file processed\n",
            "183 file processed\n",
            "184 file processed\n",
            "185 file processed\n",
            "186 file processed\n",
            "187 file processed\n",
            "188 file processed\n",
            "189 file processed\n",
            "190 file processed\n",
            "191 file processed\n",
            "192 file processed\n",
            "193 file processed\n",
            "194 file processed\n",
            "195 file processed\n",
            "196 file processed\n",
            "197 file processed\n",
            "198 file processed\n",
            "199 file processed\n",
            "200 file processed\n",
            "201 file processed\n",
            "202 file processed\n",
            "203 file processed\n",
            "204 file processed\n",
            "205 file processed\n",
            "206 file processed\n",
            "207 file processed\n",
            "208 file processed\n",
            "209 file processed\n",
            "210 file processed\n",
            "211 file processed\n",
            "212 file processed\n",
            "213 file processed\n",
            "214 file processed\n",
            "215 file processed\n",
            "216 file processed\n",
            "217 file processed\n",
            "218 file processed\n",
            "219 file processed\n",
            "220 file processed\n",
            "221 file processed\n",
            "222 file processed\n",
            "223 file processed\n",
            "224 file processed\n",
            "225 file processed\n",
            "226 file processed\n",
            "227 file processed\n",
            "228 file processed\n",
            "229 file processed\n",
            "230 file processed\n",
            "231 file processed\n",
            "232 file processed\n",
            "233 file processed\n",
            "234 file processed\n",
            "235 file processed\n",
            "236 file processed\n",
            "237 file processed\n",
            "238 file processed\n",
            "239 file processed\n",
            "240 file processed\n",
            "241 file processed\n",
            "242 file processed\n",
            "243 file processed\n",
            "244 file processed\n",
            "245 file processed\n",
            "246 file processed\n",
            "247 file processed\n",
            "248 file processed\n",
            "249 file processed\n",
            "250 file processed\n",
            "251 file processed\n",
            "252 file processed\n",
            "253 file processed\n",
            "254 file processed\n",
            "255 file processed\n",
            "256 file processed\n",
            "257 file processed\n",
            "258 file processed\n",
            "259 file processed\n",
            "260 file processed\n",
            "261 file processed\n",
            "262 file processed\n",
            "263 file processed\n",
            "264 file processed\n",
            "265 file processed\n",
            "266 file processed\n",
            "267 file processed\n",
            "268 file processed\n",
            "269 file processed\n",
            "270 file processed\n",
            "271 file processed\n",
            "272 file processed\n",
            "273 file processed\n",
            "274 file processed\n",
            "275 file processed\n",
            "276 file processed\n",
            "277 file processed\n",
            "278 file processed\n",
            "279 file processed\n",
            "280 file processed\n",
            "281 file processed\n",
            "282 file processed\n",
            "283 file processed\n",
            "284 file processed\n",
            "285 file processed\n",
            "286 file processed\n",
            "287 file processed\n",
            "288 file processed\n",
            "289 file processed\n",
            "290 file processed\n",
            "291 file processed\n",
            "292 file processed\n",
            "293 file processed\n",
            "294 file processed\n",
            "295 file processed\n",
            "296 file processed\n",
            "297 file processed\n",
            "298 file processed\n",
            "299 file processed\n",
            "300 file processed\n",
            "301 file processed\n",
            "302 file processed\n",
            "303 file processed\n",
            "304 file processed\n",
            "305 file processed\n",
            "306 file processed\n",
            "307 file processed\n",
            "308 file processed\n",
            "309 file processed\n",
            "310 file processed\n",
            "311 file processed\n",
            "312 file processed\n",
            "313 file processed\n",
            "314 file processed\n",
            "315 file processed\n",
            "316 file processed\n",
            "317 file processed\n",
            "318 file processed\n",
            "319 file processed\n",
            "320 file processed\n",
            "321 file processed\n",
            "322 file processed\n",
            "323 file processed\n",
            "324 file processed\n",
            "325 file processed\n",
            "326 file processed\n",
            "327 file processed\n",
            "328 file processed\n",
            "329 file processed\n",
            "330 file processed\n",
            "331 file processed\n",
            "332 file processed\n",
            "333 file processed\n",
            "334 file processed\n",
            "335 file processed\n",
            "336 file processed\n",
            "337 file processed\n",
            "338 file processed\n",
            "339 file processed\n",
            "340 file processed\n",
            "341 file processed\n",
            "342 file processed\n",
            "343 file processed\n",
            "344 file processed\n",
            "345 file processed\n",
            "346 file processed\n",
            "347 file processed\n",
            "348 file processed\n",
            "349 file processed\n",
            "350 file processed\n",
            "351 file processed\n",
            "352 file processed\n",
            "353 file processed\n",
            "354 file processed\n",
            "355 file processed\n",
            "356 file processed\n",
            "357 file processed\n",
            "358 file processed\n",
            "359 file processed\n",
            "360 file processed\n",
            "361 file processed\n",
            "362 file processed\n",
            "363 file processed\n",
            "364 file processed\n",
            "365 file processed\n",
            "366 file processed\n",
            "367 file processed\n",
            "368 file processed\n",
            "369 file processed\n",
            "370 file processed\n",
            "371 file processed\n",
            "372 file processed\n",
            "373 file processed\n",
            "374 file processed\n",
            "375 file processed\n",
            "376 file processed\n",
            "377 file processed\n",
            "378 file processed\n",
            "379 file processed\n",
            "380 file processed\n",
            "381 file processed\n",
            "382 file processed\n",
            "383 file processed\n",
            "384 file processed\n",
            "385 file processed\n",
            "386 file processed\n",
            "387 file processed\n",
            "388 file processed\n",
            "389 file processed\n",
            "390 file processed\n",
            "391 file processed\n",
            "392 file processed\n",
            "393 file processed\n",
            "394 file processed\n",
            "395 file processed\n",
            "396 file processed\n",
            "397 file processed\n",
            "398 file processed\n",
            "399 file processed\n",
            "400 file processed\n",
            "401 file processed\n",
            "402 file processed\n",
            "403 file processed\n",
            "404 file processed\n",
            "405 file processed\n",
            "406 file processed\n",
            "407 file processed\n",
            "408 file processed\n",
            "409 file processed\n",
            "410 file processed\n",
            "411 file processed\n",
            "412 file processed\n",
            "413 file processed\n",
            "414 file processed\n",
            "415 file processed\n",
            "416 file processed\n",
            "417 file processed\n",
            "418 file processed\n",
            "419 file processed\n",
            "420 file processed\n",
            "421 file processed\n",
            "422 file processed\n",
            "423 file processed\n",
            "424 file processed\n",
            "425 file processed\n",
            "426 file processed\n",
            "427 file processed\n",
            "428 file processed\n",
            "429 file processed\n",
            "430 file processed\n",
            "431 file processed\n",
            "432 file processed\n",
            "433 file processed\n",
            "434 file processed\n",
            "435 file processed\n",
            "436 file processed\n",
            "437 file processed\n",
            "438 file processed\n",
            "439 file processed\n",
            "440 file processed\n",
            "441 file processed\n",
            "442 file processed\n",
            "443 file processed\n",
            "444 file processed\n",
            "445 file processed\n",
            "446 file processed\n",
            "447 file processed\n",
            "448 file processed\n",
            "449 file processed\n",
            "450 file processed\n",
            "451 file processed\n",
            "452 file processed\n",
            "453 file processed\n",
            "454 file processed\n",
            "455 file processed\n",
            "456 file processed\n",
            "457 file processed\n",
            "458 file processed\n",
            "459 file processed\n",
            "460 file processed\n",
            "461 file processed\n",
            "462 file processed\n",
            "463 file processed\n",
            "464 file processed\n",
            "465 file processed\n",
            "466 file processed\n",
            "467 file processed\n",
            "468 file processed\n",
            "469 file processed\n",
            "470 file processed\n",
            "471 file processed\n",
            "472 file processed\n",
            "473 file processed\n",
            "474 file processed\n",
            "475 file processed\n",
            "476 file processed\n",
            "477 file processed\n",
            "478 file processed\n",
            "479 file processed\n",
            "480 file processed\n",
            "481 file processed\n",
            "482 file processed\n",
            "483 file processed\n",
            "484 file processed\n",
            "485 file processed\n",
            "486 file processed\n",
            "487 file processed\n",
            "488 file processed\n",
            "489 file processed\n",
            "490 file processed\n",
            "491 file processed\n",
            "492 file processed\n",
            "493 file processed\n",
            "494 file processed\n",
            "495 file processed\n",
            "496 file processed\n",
            "497 file processed\n",
            "498 file processed\n",
            "499 file processed\n",
            "500 file processed\n",
            "501 file processed\n",
            "502 file processed\n",
            "503 file processed\n",
            "504 file processed\n",
            "505 file processed\n",
            "506 file processed\n",
            "507 file processed\n",
            "508 file processed\n",
            "509 file processed\n",
            "510 file processed\n",
            "511 file processed\n",
            "512 file processed\n",
            "513 file processed\n",
            "514 file processed\n",
            "515 file processed\n",
            "516 file processed\n",
            "517 file processed\n",
            "518 file processed\n",
            "519 file processed\n",
            "520 file processed\n",
            "521 file processed\n",
            "522 file processed\n",
            "523 file processed\n",
            "524 file processed\n",
            "525 file processed\n",
            "526 file processed\n",
            "527 file processed\n",
            "528 file processed\n",
            "529 file processed\n",
            "530 file processed\n",
            "531 file processed\n",
            "532 file processed\n",
            "533 file processed\n",
            "534 file processed\n",
            "535 file processed\n",
            "536 file processed\n",
            "537 file processed\n",
            "538 file processed\n",
            "539 file processed\n",
            "540 file processed\n",
            "541 file processed\n",
            "542 file processed\n",
            "543 file processed\n",
            "544 file processed\n",
            "545 file processed\n",
            "546 file processed\n",
            "547 file processed\n",
            "548 file processed\n",
            "549 file processed\n",
            "550 file processed\n",
            "551 file processed\n",
            "552 file processed\n",
            "553 file processed\n",
            "554 file processed\n",
            "555 file processed\n",
            "556 file processed\n",
            "557 file processed\n",
            "558 file processed\n",
            "559 file processed\n",
            "560 file processed\n",
            "561 file processed\n",
            "562 file processed\n",
            "563 file processed\n",
            "564 file processed\n",
            "565 file processed\n",
            "566 file processed\n",
            "567 file processed\n",
            "568 file processed\n",
            "569 file processed\n",
            "570 file processed\n",
            "571 file processed\n",
            "572 file processed\n",
            "573 file processed\n",
            "574 file processed\n",
            "575 file processed\n",
            "576 file processed\n",
            "577 file processed\n",
            "578 file processed\n",
            "579 file processed\n",
            "580 file processed\n",
            "581 file processed\n",
            "582 file processed\n",
            "583 file processed\n",
            "584 file processed\n",
            "585 file processed\n",
            "586 file processed\n",
            "587 file processed\n",
            "588 file processed\n",
            "589 file processed\n",
            "590 file processed\n",
            "591 file processed\n",
            "592 file processed\n",
            "593 file processed\n",
            "594 file processed\n",
            "595 file processed\n",
            "596 file processed\n",
            "597 file processed\n",
            "598 file processed\n",
            "599 file processed\n",
            "600 file processed\n",
            "601 file processed\n",
            "602 file processed\n",
            "603 file processed\n",
            "604 file processed\n",
            "605 file processed\n",
            "606 file processed\n",
            "607 file processed\n",
            "608 file processed\n",
            "609 file processed\n",
            "610 file processed\n",
            "611 file processed\n",
            "612 file processed\n",
            "613 file processed\n",
            "614 file processed\n",
            "615 file processed\n",
            "616 file processed\n",
            "617 file processed\n",
            "618 file processed\n",
            "619 file processed\n",
            "620 file processed\n",
            "621 file processed\n",
            "622 file processed\n",
            "623 file processed\n",
            "624 file processed\n",
            "625 file processed\n",
            "626 file processed\n",
            "627 file processed\n",
            "628 file processed\n",
            "629 file processed\n",
            "630 file processed\n",
            "631 file processed\n",
            "632 file processed\n",
            "633 file processed\n",
            "634 file processed\n",
            "635 file processed\n",
            "636 file processed\n",
            "637 file processed\n",
            "638 file processed\n",
            "639 file processed\n",
            "640 file processed\n",
            "641 file processed\n",
            "642 file processed\n",
            "643 file processed\n",
            "644 file processed\n",
            "645 file processed\n",
            "646 file processed\n",
            "647 file processed\n",
            "648 file processed\n",
            "649 file processed\n",
            "650 file processed\n",
            "651 file processed\n",
            "652 file processed\n",
            "653 file processed\n",
            "654 file processed\n",
            "655 file processed\n",
            "656 file processed\n",
            "657 file processed\n",
            "658 file processed\n",
            "659 file processed\n",
            "660 file processed\n",
            "661 file processed\n",
            "662 file processed\n",
            "663 file processed\n",
            "664 file processed\n",
            "665 file processed\n",
            "666 file processed\n",
            "667 file processed\n",
            "668 file processed\n",
            "669 file processed\n",
            "670 file processed\n",
            "671 file processed\n",
            "672 file processed\n",
            "673 file processed\n",
            "674 file processed\n",
            "675 file processed\n",
            "676 file processed\n",
            "677 file processed\n",
            "678 file processed\n",
            "679 file processed\n",
            "680 file processed\n",
            "681 file processed\n",
            "682 file processed\n",
            "683 file processed\n",
            "684 file processed\n",
            "685 file processed\n",
            "686 file processed\n",
            "687 file processed\n",
            "688 file processed\n",
            "689 file processed\n",
            "690 file processed\n",
            "691 file processed\n",
            "692 file processed\n",
            "693 file processed\n",
            "694 file processed\n",
            "695 file processed\n",
            "696 file processed\n",
            "697 file processed\n",
            "698 file processed\n",
            "699 file processed\n",
            "700 file processed\n",
            "701 file processed\n",
            "702 file processed\n",
            "703 file processed\n",
            "704 file processed\n",
            "705 file processed\n",
            "706 file processed\n",
            "707 file processed\n",
            "708 file processed\n",
            "709 file processed\n",
            "710 file processed\n",
            "711 file processed\n",
            "712 file processed\n",
            "713 file processed\n",
            "714 file processed\n",
            "715 file processed\n",
            "716 file processed\n",
            "717 file processed\n",
            "718 file processed\n",
            "719 file processed\n",
            "720 file processed\n",
            "721 file processed\n",
            "722 file processed\n",
            "723 file processed\n",
            "724 file processed\n",
            "725 file processed\n",
            "726 file processed\n",
            "727 file processed\n",
            "728 file processed\n",
            "729 file processed\n",
            "730 file processed\n",
            "731 file processed\n",
            "732 file processed\n",
            "733 file processed\n",
            "734 file processed\n",
            "735 file processed\n",
            "736 file processed\n",
            "737 file processed\n",
            "738 file processed\n",
            "739 file processed\n",
            "740 file processed\n",
            "741 file processed\n",
            "742 file processed\n",
            "743 file processed\n",
            "744 file processed\n",
            "745 file processed\n",
            "746 file processed\n",
            "747 file processed\n",
            "748 file processed\n",
            "749 file processed\n",
            "750 file processed\n",
            "751 file processed\n",
            "752 file processed\n",
            "753 file processed\n",
            "754 file processed\n",
            "755 file processed\n",
            "756 file processed\n",
            "757 file processed\n",
            "758 file processed\n",
            "759 file processed\n",
            "760 file processed\n",
            "761 file processed\n",
            "762 file processed\n",
            "763 file processed\n",
            "764 file processed\n",
            "765 file processed\n",
            "766 file processed\n",
            "767 file processed\n",
            "768 file processed\n",
            "769 file processed\n",
            "770 file processed\n",
            "771 file processed\n",
            "772 file processed\n",
            "773 file processed\n",
            "774 file processed\n",
            "775 file processed\n",
            "776 file processed\n",
            "777 file processed\n",
            "778 file processed\n",
            "779 file processed\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.save('/content/drive/My Drive/tamp_conf',tamp_conf)"
      ],
      "metadata": {
        "id": "kStcl8ciF55o",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 165
        },
        "outputId": "1aefbc8f-ca42-47e8-c400-8eff40e5173c"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-587b81366a0e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive/My Drive/tamp_conf'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtamp_conf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'tamp_conf' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sklearn.metrics as sm\n",
        "from matplotlib import pyplot as plt"
      ],
      "metadata": {
        "id": "j9UVPcnVFyyb"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ntc=np.load('/content/drive/My Drive/non_tamp_conf_EucDis.npy',allow_pickle=True)\n",
        "ntc.shape"
      ],
      "metadata": {
        "id": "VFpp2vfjF0qj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7e186404-2227-418c-8c20-50554925a512"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(430,)"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tamp_conf = np.load('/content/drive/My Drive/tamp_conf.npy',allow_pickle=True)\n",
        "tamp_conf.shape"
      ],
      "metadata": {
        "id": "PPFklJfeGAsl",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 321
        },
        "outputId": "1905fa88-96ac-47dd-981d-01a4bc5d473e"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-6469b5ae03c4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtamp_conf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive/My Drive/tamp_conf.npy'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mallow_pickle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mtamp_conf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/numpy/lib/npyio.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(file, mmap_mode, allow_pickle, fix_imports, encoding)\u001b[0m\n\u001b[1;32m    415\u001b[0m             \u001b[0mown_fid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    416\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 417\u001b[0;31m             \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstack\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menter_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos_fspath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    418\u001b[0m             \u001b[0mown_fid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    419\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/drive/My Drive/tamp_conf.npy'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fig,ax=plt.subplots(1,1)\n",
        "\n",
        "ax.hist(ntc, bins = [0,1,2,3,4,5,6,7,8,9])\n",
        "ax.hist(tamp_conf, bins = [0,1,2,3,4,5,6,7,8,9])\n",
        "ax.set_title(\"Histograms for confidence levels\")\n",
        "ax.set_xticks([0,1,2,3,4,5,6,7,8,9])\n",
        "ax.set_xlabel('confidence levels')\n",
        "ax.set_ylabel('pdf')\n",
        "plt.legend(['Real videos confidence', 'Fake videos confidence'])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "SrMAYu6SGFL8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# combining tampered and non tampered confidences\n",
        "\n",
        "conf=[]\n",
        "for i in ntc:\n",
        "  conf.append(i)\n",
        "for i in tamp_conf:\n",
        "  conf.append(i)\n",
        "len(conf)"
      ],
      "metadata": {
        "id": "q95ZDtUmGH1w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# true labels for tampered and non tampered videos\n",
        "\n",
        "true_label=[1 for i in range(430)]\n",
        "true_labe=[0 for i in range(1287)]\n",
        "\n",
        "y_true=true_label+true_labe\n",
        "len(y_true)"
      ],
      "metadata": {
        "id": "aPwg4pmWGPY1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "40a028ff-0154-4480-cf1e-71d78613ab74"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1717"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# finding threshold to classify real or fake. Checking values between 2 to 4.\n",
        "\n",
        "threshold=[]\n",
        "for i in conf:\n",
        "  if i>2 and i<4:\n",
        "    threshold.append(i)\n",
        "print(len(threshold))\n",
        "threshold.sort()"
      ],
      "metadata": {
        "id": "PN72DmRWGVJk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c88c40ae-8d7b-4272-ca28-a39d2cf924db"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "223\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "recall_metric=[]\n",
        "pr=[]\n",
        "for i in threshold:\n",
        "  pred=[]\n",
        "  for j in conf:\n",
        "    if j>i:\n",
        "      pred.append(1)\n",
        "    else:\n",
        "      pred.append(0)\n",
        "  recall_metric.append(sm.recall_score(y_true, pred))\n",
        "  pr.append(sm.precision_score(y_true, pred))"
      ],
      "metadata": {
        "id": "-M9hYkb4GaEH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "max(pr),np.argmax(pr)"
      ],
      "metadata": {
        "id": "TKqL6wB7GgCM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "threshold[354]"
      ],
      "metadata": {
        "id": "tKvj2nh9Gjbb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred=[]\n",
        "for i in conf:\n",
        "  if i>threshold[354]:\n",
        "    y_pred.append(1)\n",
        "  else:\n",
        "    y_pred.append(0)\n",
        "\n",
        "print(sm.accuracy_score(y_true, y_pred))\n",
        "print(sm.f1_score(y_true, y_pred))\n",
        "print(sm.precision_score(y_true, y_pred))\n",
        "print(sm.recall_score(y_true, y_pred))   \n",
        "print(sm.roc_auc_score(y_true, y_pred))\n",
        "sm.confusion_matrix(y_true, y_pred)"
      ],
      "metadata": {
        "id": "bHFUXTerGm5G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred=[]\n",
        "for i in conf:\n",
        "  if i>3.5:\n",
        "    y_pred.append(1)\n",
        "  else:\n",
        "    y_pred.append(0)\n",
        "\n",
        "\n",
        "print(sm.accuracy_score(y_true, y_pred))\n",
        "print(sm.f1_score(y_true, y_pred))\n",
        "print(sm.precision_score(y_true, y_pred))\n",
        "print(sm.recall_score(y_true, y_pred))   \n",
        "print(sm.roc_auc_score(y_true, y_pred))\n",
        "sm.confusion_matrix(y_true, y_pred)"
      ],
      "metadata": {
        "id": "9oQGXb7wGuOP"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}